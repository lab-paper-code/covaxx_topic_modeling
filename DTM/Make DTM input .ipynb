{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442cf3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54d1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather('./Datasets/dataset.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b14009b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197515"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6086c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_file = \"./Datasets/RawDatasets/txt/stopwords.txt\"\n",
    "stop_words =  [line.strip() for line in open(stop_word_file, encoding=\"utf-8\").readlines()]\n",
    "for i in range(len(data)):\n",
    "    temp = data['okt'][i]\n",
    "    data['okt'][i] = [word for word in temp if (not word in stop_words)]\n",
    "index = []\n",
    "for i in range(len(data)):\n",
    "    if len(data.okt[i]) < 1:\n",
    "        index.append(i)\n",
    "data = data.drop(index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9180dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp'] = data['date'].astype(str)\n",
    "data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce79e53",
   "metadata": {},
   "source": [
    "# phase1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1fecfece",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_timeline_map = {\n",
    "     '202102':'0',\n",
    "     '202103':'1',\n",
    "     '202104':'2',\n",
    "     '202105':'3',\n",
    "     '202106':'4',\n",
    "     '202107':'5',\n",
    "     '202108':'6',\n",
    "     '202109':'7',\n",
    "     '202110':'8',\n",
    "     '202111':'9',\n",
    "     '202112':'10',\n",
    "     '202201':'11',\n",
    "     '202202':'12',\n",
    "     '202203':'13',\n",
    "     '202204':'14',\n",
    "     '202205':'15',\n",
    "     '202206':'16',\n",
    "     '202207':'17',\n",
    "     '202208':'18',\n",
    "     '202209':'19',\n",
    "     '202210':'20',\n",
    "     '202211':'21',\n",
    "     '202212':'22',\n",
    "     '202301':'23',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b7570b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('./Datasets/dtm_input_all.txt','w')\n",
    "for i in range(len(data)):\n",
    "    date = data.loc[i].timestamp.replace('-','')\n",
    "    date = date[:6]\n",
    "    timepoint = all_timeline_map.get(f'{date}')\n",
    "    temp = timepoint+\" \"+' '.join(data.loc[i].okt)+'\\n'\n",
    "    output.write(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ebab65",
   "metadata": {},
   "source": [
    "# phase2\n",
    "\n",
    "similarity가 증가하다가 감소하는 시점을 기준으로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1cf5e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "phase1_data = data[data['date'].dt.date < date(2021,6,1)]\n",
    "\n",
    "phase2_data = data[data['date'].dt.date < date(2021,10,1)]\n",
    "phase2_data = phase2_data[phase2_data['date'].dt.date >= date(2021,6,1)]\n",
    "\n",
    "phase3_data = data[data['date'].dt.date < date(2022,6,1)]\n",
    "phase3_data = phase3_data[phase3_data['date'].dt.date >= date(2021,10,1)]\n",
    "\n",
    "phase4_data = data[data['date'].dt.date < date(2022,9,1)]\n",
    "phase4_data = phase4_data[phase4_data['date'].dt.date >= date(2022,6,1)]\n",
    "\n",
    "phase5_data = data[data['date'].dt.date >=  date(2022,9,1)]\n",
    "\n",
    "phase1_data = phase1_data.reset_index(drop=True)\n",
    "phase2_data = phase2_data.reset_index(drop=True)\n",
    "phase3_data = phase3_data.reset_index(drop=True)\n",
    "phase4_data = phase4_data.reset_index(drop=True)\n",
    "phase5_data = phase5_data.reset_index(drop=True)\n",
    "phase6_data = phase6_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "696b1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = data[data['date'].dt.date >=  date(2022,6,1)]\n",
    "temp_data = temp_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a204ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase1_timeline_map={\n",
    "     '202102':'0',\n",
    "     '202103':'1',\n",
    "     '202104':'2',\n",
    "     '202105':'3',\n",
    "}\n",
    "phase2_timeline_map={\n",
    "    \n",
    "     '202106':'0',\n",
    "     '202107':'1',\n",
    "     '202108':'2',\n",
    "     '202109':'3',\n",
    "}\n",
    "phase3_timeline_map={\n",
    "    \n",
    "     '202110':'0',\n",
    "     '202111':'1',\n",
    "     '202112':'2',\n",
    "     '202201':'3',\n",
    "     '202202':'4',\n",
    "     '202203':'5',\n",
    "     '202204':'6',\n",
    "     '202205':'7',\n",
    "}\n",
    "phase4_timeline_map={\n",
    "     '202206':'0',\n",
    "     '202207':'1',\n",
    "     '202208':'2',\n",
    "}\n",
    "phase5_timeline_map={\n",
    "    \n",
    "     '202209':'0',\n",
    "     '202210':'1',\n",
    "     '202211':'2',\n",
    "    '202212':'3',\n",
    "     '202301':'4',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11342f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('./Datasets/dtm_input_section1.txt','w')    \n",
    "for i in range(len(phase1_data)):\n",
    "    date = phase1_data.loc[i].timestamp.replace('-','')\n",
    "    date = date[:6]\n",
    "    timepoint = phase1_timeline_map.get(f'{date}')\n",
    "    temp = timepoint+\" \"+' '.join(phase1_data.loc[i].okt)+'\\n'\n",
    "    output.write(temp)\n",
    "    \n",
    "output = open('./Datasets/dtm_input_section2.txt','w')\n",
    "for i in range(len(phase2_data)):\n",
    "    date = phase2_data.loc[i].timestamp.replace('-','')\n",
    "    date = date[:6]\n",
    "    timepoint = phase2_timeline_map.get(f'{date}')\n",
    "    temp = timepoint+\" \"+' '.join(phase2_data.loc[i].okt)+'\\n'\n",
    "    output.write(temp)\n",
    "    \n",
    "output = open('./Datasets/dtm_input_section3.txt','w')    \n",
    "for i in range(len(phase3_data)):\n",
    "    date = phase3_data.loc[i].timestamp.replace('-','')\n",
    "    date = date[:6]\n",
    "    timepoint = phase3_timeline_map.get(f'{date}')\n",
    "    temp = timepoint+\" \"+' '.join(phase3_data.loc[i].okt)+'\\n'\n",
    "    output.write(temp)\n",
    "    \n",
    "output = open('./Datasets/dtm_input_section4.txt','w')    \n",
    "for i in range(len(phase4_data)):\n",
    "    date = phase4_data.loc[i].timestamp.replace('-','')\n",
    "    date = date[:6]\n",
    "    timepoint = phase4_timeline_map.get(f'{date}')\n",
    "    temp = timepoint+\" \"+' '.join(phase4_data.loc[i].okt)+'\\n'\n",
    "    output.write(temp)\n",
    "    \n",
    "    \n",
    "output = open('./Datasets/dtm_input_section5.txt','w')    \n",
    "for i in range(len(phase5_data)):\n",
    "    date = phase5_data.loc[i].timestamp.replace('-','')\n",
    "    date = date[:6]\n",
    "    timepoint = phase5_timeline_map.get(f'{date}')\n",
    "    temp = timepoint+\" \"+' '.join(phase5_data.loc[i].okt)+'\\n'\n",
    "    output.write(temp)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:harin]",
   "language": "python",
   "name": "conda-env-harin-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
